# 第七章 NLP特征的案例分析

> 本章我们将探讨具体的NLP分类任务示例,以及适合它们的特征.我们希望确保设计的网络能够有效地利用可用的信号,或者通过使用特征工程直接访问它们,或者通过设计网络结构来暴露所需的信号,或者在训练模型时将它们作为额外添加的损失信号.

## 文本分类:语音识别

**语音识别任务:**给定一个文档或一个句子,希望将其归类为一组固定的语言.一个类似的任务是编码检测,相应的特征表示是字节级二元文法词袋.

## 文本分类:主题分类

**主题分类任务:**对于给定的文档,需要将它归类为一组预定义的主题(如经济,政治,体育,休闲,八卦,生活方式等).

在这类任务中,以词为基本单位.词序对这个任务很有帮助.比如,词袋模型,n元组模型.

在没有足够的训练样本的时候,可通过对文档进行预处理来达到更好的效果,如将每个词替换为对应的词元(lemma).也可以通过诸如词簇或词嵌入向量等分布特征来替换或补充单词.

## 文本分类:作者归属

**作者归属任务:**对于给定的文本,推断它的作者身份,或者文本的作者的其他特征,例如他们的性别,年龄或者母语.

用于解决此任务的信息类型与主题分类非常不同:线索很微妙,涉及**文本的文体属性**,而不是**内容词**.

**特征的选择**应该避开内容词,并侧重于更多的文体属性.对于这些任务,一个好特征集专注于**词性(POS)标签和功能词**.

**功能词**的一个很好的近似是一个大规模语料库中排在最前的300个词或频繁出现的词的列表.<u>着眼于这些特征,我们可以捕捉到写作中微妙的问题变化,对于作者来说,这是独特的并且很难伪造</u>

**作者归属任务的特征集合:**功能词与代词词袋,词性词袋,词性的二元文法,三元文法,四元文法词袋,功能词的密度(即功能词与文本窗口中的内容词数量之间的比值),删除内容词后的功能词二元文法词袋与连贯功能词之间的距离分布.

> **文体属性**
>
> 我们可以通过观察内容词获取年龄或性别-----一个人的年龄和性别与它们所写的话题以及所使用的语言记录之间有很强的相关性.

## 上下文中的单词:词性标注

**词性标注任务:**给定一个句子,我们需要给句子中的每个单词分配正确的词性.它通常被建模为一个结构化任务.

**词性集合:**在本书中使用的是通用树库项目[McDonald et al., 2013, Nivre et al.,2015]中的词性集合,包含17个词性标签.

**词性标注任务的信息来源**分为内部线索(基于单词本身)和外部线索(基于上下文).

**内部线索:**包括词的识别(例如,有些词比其他词更有可能是名词),前缀,后缀,正字词的形状(在英语中,以ed结尾的单词很可能是过去时态动词),以un开头的单词可能是形容词,而以大写字母开头的单词很可能是专有名词),以及单词在大语料库中的频率(例如,罕见的词更可能是名词).

**外部线索:**单词的标识,前缀和当前单词周围单词的后缀,以及前面单词的词性预测结果.

> **重叠特征**
>
> 如果将单词形式化为特征,为什么需要前缀和后缀?
>
> 原因是,如果遇到一个在训练中没有看到的词(**未登录词**)或很少出现的词(**罕见的词**),我们可能没有足够多的信息来做出决定.在这种情况下,最好将前缀和后缀作为补偿,这可以提供有用的提示.通过包括前缀和后缀以及在训练中多次观察到的单词,我们**允许学习算法更好的调整它们的权重,并希望在遇到未登录词时能够正确的使用它们.**

除了上述提到的线索之外,分布信息(如词簇或目标词和周围的单词的嵌入表示)也很有用,特别是**对于在训练语料库中没有看到的单词**,因为相比于不同的词性标签的单词,具有类似的词性标签的词往往出现在更相似的上下文.

## 上下文中的单词:命名实体识别

**命名实体任务:**给定一篇文档,需要找到命名实体,将它们归类为一组预定义的类别,如位置,机构,人物或其他.**值得注意的一点是,这项任务是依赖于上下文的,比如milan可以代表位置(城市),也可以代表机构(足球队)**.

**NER**<u>是一个序列分割任务----它分配标记括号超过非重叠的句子跨度,但它通常被建模为序列标注任务,类似于词性标注.</u>使用标注来解决分割任务一般都是**用BIO标签**.

与词性标注相同,该任务是结构化的,因为不同单词的标注会相互作用(比如在连续的词上趋向保持相同的实体类型)

###**任务特征选择**

为该任务设置的核心特征类似于**词性标注任务中的特征**,它依赖于距离焦点单词每侧长度为2的窗口中的单词(词的前缀和后缀信息).

除了词性标注任务的特征对我们很有用之外,我们可能要通过单词周围的**共现单词**来确定目标词的身份,以及**指示函数**用以检查该词是否是预编译列表中的人物,位置和机构.

**分布特征**(如词簇或词向量)对NER任务也是非常有用的.

> 对于NER任务中特征全面而综合的讨论请参见Ratinov和Roth[2009].

## 上下文中单词的语言特征:介词词义消歧

介词如on,in,with以及for等,用于将谓语与它的论元以及名词与它的前置修饰连接起来.介词非常常见,也易引起歧义.

**介词消歧任务:**从有限的语义集合中选择正确的意义分配给上下文中的介词.

> Schneideret等人[2015,2016]提出了一个统一的涵盖了许多介词的语义集合,并提供了一个小规模的在线评论的标注语料库,其中涵盖4250个介词并注释其语义.该任务更早的语义清单和标注的语料库也是可用的.见Litkowski和Hargraves[2005,2007],Srikumar和Roth[2013a]

### 介词语义消歧特征

哪些是介词语义消歧任务中较好的特征集合?(本文的特征集合是受Hovy等人[2010]工作的启发).

一般认为,从富含信息的角度来说,一个固定的围绕介词的窗口是不理想的.大多词的窗口信息并不具有很大的信息量甚至有误导性.

我们需要一个更好的机制来选择信息量较大的上下文.

**一种方法是使用启发式规则**,例如"左边的第一个动词"和"右边的第一个名词";在语言学方面,这种启发式能够帮助我们捕获介词的调控器和对象.通过知道介词的语义以及它的调控器和对象,并使用关于单词的细粒度语义的推理过程,我们可以在许多情况下推断介词的语义.**提取对象和调控器的启发式规则要求使用词性标注工具,以识别名词和动词**.

**更健壮的方法是使用依存分析树**:从语法树中可以轻松地获取调控器和对象信息,从而减少了对复杂启发式规则的需要.

**更加鲁棒的方法:**用于生成树的分析器也可能是错误的,为了鲁棒性,我们可以同时查看从解析器中提取的调控器和对象,以及使用启发式提取的调控器和对象.并将这四个作为特征来源,让学习过程决定哪一来源更加可靠以及如何权衡它们.

在提取了调控器和对象(也许还有与调控器和对象相邻的词)之后,利用它们作为进一步特征提取的基础.对于每个项目,我们可以提取以下信息:

- 单词确切的字面形式
- 单词的词元
- 单词的词性
- 单词的前缀和后缀(对程度,数量,顺序的指示,如ultra-,poly-,post-, 以及代理与非代理动词的区别)
- 词簇以及词的分布式向量表示

在允许外部词汇资源的使用,并且不介意扩大特征空间,Hovy等人[2010]发现使用基于WordNet的特征也很有用.对于每个调控器和对象,我们可以提取许多WordNet指示器,例如:

- 单词是否具有WordNet词项
- 单词第一个同义词集合的上位词
- 单词所有同义词集合的上位词
- 单词第一个同义词集合的同义词
- 单词所有同义词集合的同义词
- 单词定义的所有词项
- 单词的超语义(super-senses,在WordNet中也被称为编撰文件,表明概念.)
- 其他指示器的变种

### 总结

介词语义消歧任务是一个高层次的语义分类问题.为此,我们需要一组无法从字面中轻易推断出来的特征,并且可以利用从语言预处理(即词性标注和句法分析)以及手工编撰的语义词汇资源中选择的信息片段.



## 上下文中单词的关系:弧分解分析

在依存任务中,给定一个句子,需要返回一个语法依存树.每个词语都被分配了一个父词语,除了句子中主词语的根节点是"root"节点.

> 关于依存分析任务的更多信息,以及其语言学基础和解决方案,请参见kubler等人[2008].

### 任务建模

- 弧分解法(arc-factored)[McDonald et al., 2005]

  > 其中每个可能的$n^2$个词-词关系(arc)被分配一个独立的分数,然后我们搜索得到一个最大化总体分数的有效的树.分数通过训练好的**打分函数ARCSCORE(h,m,sent)**分配,接收给定的句子以及句子中分配的候选词对h和m(h是候选头词的索引,m是候选修饰词的索引).
  >
  > 训练打分函数以使其与搜索程序一同很好的工作将在第19章中讨论.

  **打分函数需要用到的特征**

  - 头词的字面形式以及词性
  - 修饰词的字面形式以及词性(一些词几乎不可能是头词或者修饰词,无论它们与谁连接,比如限定词the,a通常是修饰词,而不会是头词)
  - 与头词在同一窗口(窗口大小为2)中的单词与词性,以及其位置.
  - 与修饰词在同一窗口(窗口大小为2)中的单词与词性,以及其位置(需要窗口信息来给单词提供一些上下文.不同的上下文中,单词的行为不同)

  > 由于依存树的训练语料库的规模通常相当有限,使用词簇或预训练的词嵌入等分布信息来补充或替换单词可能是一个好主意,这将使类似的词具有泛化性,对于没有被训练数据很好覆盖的词也是有用的.

  

